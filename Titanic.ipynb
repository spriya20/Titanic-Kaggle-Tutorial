{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = pd.read_csv(r\"data\\train.csv\", header=0,delimiter=\",\", quoting=1)\n",
    "# train, val = train_test_split(data)\n",
    "test = pd.read_csv(r\"data\\test.csv\", header=0,delimiter=\",\", quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "Title            0\n",
       "Emb              0\n",
       "FamilySize       0\n",
       "FamSize          0\n",
       "AgeBands         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "Title            0\n",
       "Emb              0\n",
       "FamilySize       0\n",
       "FamSize          0\n",
       "AgeBands         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = data[data[\"Survived\"]==1]\n",
    "not_survived = data[data[\"Survived\"]==0]\n",
    "print(len(survived),len(not_survived),len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"Pclass\").Survived.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Title\"]=data.Name.str.extract(r\" ([A-z]\\w+)\\. \")\n",
    "test[\"Title\"]=test.Name.str.extract(r\" ([A-z]\\w+)\\. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Titles = test[\"Title\"].value_counts()\n",
    "data_Titles = data[\"Title\"].value_counts()\n",
    "data_survprob = data.groupby(\"Title\").Survived.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Data   Test  Survival Rate\n",
      "Capt        1.0    NaN       0.000000\n",
      "Col         2.0    2.0       0.500000\n",
      "Countess    1.0    NaN       1.000000\n",
      "Don         1.0    NaN       0.000000\n",
      "Dona        NaN    1.0            NaN\n",
      "Dr          7.0    1.0       0.428571\n",
      "Jonkheer    1.0    NaN       0.000000\n",
      "Lady        1.0    NaN       1.000000\n",
      "Major       2.0    NaN       0.500000\n",
      "Master     40.0   21.0       0.575000\n",
      "Miss      182.0   78.0       0.697802\n",
      "Mlle        2.0    NaN       1.000000\n",
      "Mme         1.0    NaN       1.000000\n",
      "Mr        517.0  240.0       0.156673\n",
      "Mrs       125.0   72.0       0.792000\n",
      "Ms          1.0    1.0       1.000000\n",
      "Rev         6.0    2.0       0.000000\n",
      "Sir         1.0    NaN       1.000000\n"
     ]
    }
   ],
   "source": [
    "comp = pd.DataFrame({\"Data\": data_Titles,\"Test\":test_Titles, \"Survival Rate\": data_survprob})\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data[\"Sex\"],[data[\"Pclass\"],data[\"Survived\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Embarked\",\"Survived\"]].groupby(\"Embarked\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"Pclass\").Fare.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()\n",
    "# data.describe(include=\"all\")\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agebands = [0,1,2,3,4,5]\n",
    "data[\"AgeBands\"]=pd.cut(data[\"Age\"],bins=[0,5,18,35,50,65,85],labels=agebands)\n",
    "# data[\"AgeBands\"]=pd.cut(data[\"Age\"],bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Survived\",\"AgeBands\"]].groupby(\"AgeBands\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Title\"]=data.Name.str.extract(r\" ([A-z]\\w+)\\. \")\n",
    "test[\"Title\"]=test.Name.str.extract(r\" ([A-z]\\w+)\\. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ms -> Miss, \n",
    "Titles = [\"Mr\", \"Miss\", \"Mrs\", \"Master\", \"Dr\", \"Rev\", \"Others\"]\n",
    "TitleMap = {Titles[i]:i for i in range(len(Titles))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = [data, test]\n",
    "for dataset in train_test_data:\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({\"female\":0, \"male\":1}).astype(\"category\")\n",
    "    dataset[\"Embarked\"] = dataset.Embarked.fillna(\"S\")\n",
    "    dataset[\"Emb\"] = dataset[\"Embarked\"].map({\"C\":1,\"Q\":2,\"S\":3}).astype(\"category\")\n",
    "    dataset[\"Age\"] = dataset[\"Age\"].fillna(30)\n",
    "    dataset[\"FamilySize\"] = dataset.SibSp + dataset.Parch +1\n",
    "    famlabels = [0,1,2]\n",
    "    dataset[\"FamSize\"] = pd.cut(dataset[\"FamilySize\"],bins=[0,1,4,11],labels=famlabels)\n",
    "    agebands = [0,1,2,3,4,5]\n",
    "    dataset[\"AgeBands\"]=pd.cut(dataset[\"Age\"],bins=[0,5,18,35,50,65,85],labels=agebands)\n",
    "    dataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace([\"Ms\",\"Mlle\",\"Mme\"],\"Miss\")\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].apply(lambda title: title if title in Titles else \"Others\")\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].map(TitleMap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age        0\n",
       "Emb        0\n",
       "Pclass     0\n",
       "FamSize    0\n",
       "Title      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = [\"AgeBands\",\"Sex\",\"Emb\",\"Pclass\",\"FamSize\",\"Title\"]\n",
    "features = [\"Age\",\"Emb\",\"Pclass\",\"FamSize\",\"Title\"]\n",
    "data[features].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "0.42     1.0\n",
      "0.67     1.0\n",
      "0.75     1.0\n",
      "0.83     1.0\n",
      "0.92     1.0\n",
      "        ... \n",
      "70.00    0.0\n",
      "70.50    0.0\n",
      "71.00    0.0\n",
      "74.00    0.0\n",
      "80.00    1.0\n",
      "Name: Survived, Length: 88, dtype: float64\n",
      "Emb\n",
      "1    0.553571\n",
      "2    0.389610\n",
      "3    0.339009\n",
      "Name: Survived, dtype: float64\n",
      "Pclass\n",
      "1    0.629630\n",
      "2    0.472826\n",
      "3    0.242363\n",
      "Name: Survived, dtype: float64\n",
      "FamSize\n",
      "0    0.303538\n",
      "1    0.578767\n",
      "2    0.161290\n",
      "Name: Survived, dtype: float64\n",
      "Title\n",
      "0    0.156673\n",
      "1    0.704301\n",
      "2    0.792000\n",
      "3    0.575000\n",
      "4    0.428571\n",
      "5    0.000000\n",
      "6    0.500000\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for col in features:\n",
    "    print(data.groupby(col).Survived.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Survived\n",
      "AgeBands          \n",
      "0         0.704545\n",
      "1         0.410526\n",
      "2         0.353271\n",
      "3         0.398693\n",
      "4         0.375000\n",
      "5         0.125000\n",
      "     Survived\n",
      "Emb          \n",
      "1    0.553571\n",
      "2    0.389610\n",
      "3    0.339009\n",
      "        Survived\n",
      "Pclass          \n",
      "1       0.629630\n",
      "2       0.472826\n",
      "3       0.242363\n",
      "         Survived\n",
      "FamSize          \n",
      "0        0.303538\n",
      "1        0.578767\n",
      "2        0.161290\n",
      "       Survived\n",
      "Title          \n",
      "0      0.156673\n",
      "1      0.704301\n",
      "2      0.792000\n",
      "3      0.575000\n",
      "4      0.428571\n",
      "5      0.000000\n",
      "6      0.500000\n"
     ]
    }
   ],
   "source": [
    "for feat in features:\n",
    "    print(data[[\"Survived\",feat]].groupby(feat).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(data[features],data[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.48 83.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priya\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\Priya\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier().fit(train_x,train_y)\n",
    "val_acc_knn = round(clf_knn.score(val_x,val_y)*100,2)\n",
    "train_acc_knn = round(clf_knn.score(train_x,train_y)*100,2)\n",
    "print(val_acc_knn,train_acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.06 74.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_logreg = LogisticRegression().fit(train_x,train_y)\n",
    "val_acc_logreg = round(clf_logreg.score(val_x,val_y)*100,2)\n",
    "train_acc_logreg = round(clf_logreg.score(train_x,train_y)*100,2)\n",
    "print(val_acc_logreg,train_acc_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.68 62.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC().fit(train_x,train_y)\n",
    "val_acc_svc = round(clf_svc.score(val_x,val_y)*100,2)\n",
    "train_acc_svc = round(clf_svc.score(train_x,train_y)*100,2)\n",
    "print(val_acc_svc,train_acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.03 93.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier().fit(train_x,train_y)\n",
    "val_acc_dt = round(clf_dt.score(val_x,val_y)*100,2)\n",
    "train_acc_dt = round(clf_dt.score(train_x,train_y)*100,2)\n",
    "print(val_acc_dt,train_acc_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.27 93.26\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier().fit(train_x,train_y)\n",
    "val_acc_rf = round(clf_rf.score(val_x,val_y)*100,2)\n",
    "train_acc_rf = round(clf_rf.score(train_x,train_y)*100,2)\n",
    "print(val_acc_rf,train_acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.57000\n",
      "[1]\tvalidation_0-logloss:0.50716\n",
      "[2]\tvalidation_0-logloss:0.46929\n",
      "[3]\tvalidation_0-logloss:0.44839\n",
      "[4]\tvalidation_0-logloss:0.43935\n",
      "[5]\tvalidation_0-logloss:0.43151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\tvalidation_0-logloss:0.42778\n",
      "[7]\tvalidation_0-logloss:0.43103\n",
      "[8]\tvalidation_0-logloss:0.43464\n",
      "[9]\tvalidation_0-logloss:0.43513\n",
      "[10]\tvalidation_0-logloss:0.43744\n",
      "81.61 86.08\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "clf_xgb = xgb.XGBClassifier(tree_method=\"hist\",enable_categorical=True,early_stopping_rounds=5)\n",
    "clf_xgb.fit(train_x,train_y, eval_set=[(val_x,val_y)])\n",
    "val_acc_xgb = round(clf_xgb.score(val_x,val_y)*100,2)\n",
    "train_acc_xgb = round(clf_xgb.score(train_x,train_y)*100,2)\n",
    "print(val_acc_xgb,train_acc_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.24 87.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_gbc =GradientBoostingClassifier().fit(data[features],data[\"Survived\"])\n",
    "# clf_gbc =GradientBoostingClassifier().fit(train_x,train_y)\n",
    "val_acc_gbc = round(clf_gbc.score(val_x,val_y)*100,2)\n",
    "train_acc_gbc = round(clf_gbc.score(train_x,train_y)*100,2)\n",
    "print(val_acc_gbc,train_acc_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_knn = KNeighborsClassifier().fit(data[features],data[\"Survived\"])\n",
    "# clf = SVC().fit(data[features],data[\"Survived\"])\n",
    "clf = clf_gbc\n",
    "result = clf.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"PassengerId\":test[\"PassengerId\"], \"Survived\":result} )\n",
    "output.to_csv(\"Output\\\\\"+\"GCB_1.csv\", index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier().fit(data[features],data[\"Survived\"])\n",
    "result = clf.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# candidate_estimators = [5,10,25,50,100,250]\n",
    "# t_b = np.inf\n",
    "# b_e = 0\n",
    "# for est in candidate_estimators:\n",
    "#     m_n = 0\n",
    "#     m_score = np.inf\n",
    "#     scores = []\n",
    "#     for nodes in candidate_max_leaf_nodes:\n",
    "#         forest = RandomForestClassifier(max_leaf_nodes=nodes, n_estimators=est)\n",
    "#         forest.fit(x,y)\n",
    "#         score = forest.score(val_x,val_y)\n",
    "#         scores.append(score)\n",
    "#         if score<m_score:\n",
    "#             m_n = nodes\n",
    "#             m_score = score\n",
    "#     if m_score<t_b:\n",
    "#         t_b = m_score\n",
    "#         b_e = est\n",
    "#     print(est,\" estimators, \",m_n,\" nodes with score: \", m_score)\n",
    "#     print(scores)\n",
    "# print(\"Best config: \",b_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
